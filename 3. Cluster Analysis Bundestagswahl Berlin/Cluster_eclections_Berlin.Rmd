---
title: "Wählerschaft in Berlin mit Fokus auf die Wahllokale im Bezirk Pankow, TEIL 1"
subtitle: "Clusteranalyse der Bundestagswahl 2017"
author: "Dr. Magdalena Blum-Oeste"
date: "7/22/2020"
output:
   rmdformats::readthedown:
    self_contained: true
    thumbnails: false # if true then figures small as thumbnails
    lightbox: true
    gallery: false
    highlight: tango
    #highlight: github
---
<style>

sidebar {
    background-color: rgb(299, 43, 80);
}

#sidebar {
    background: #000000;
    background-color: #000000;
    z-index: 200;
    font-size: 16px;
}

p{
    font-family: Clear Sans;
    font-size:16px;
    line-height:24px;
    margin:0px 0px 12px 0px;
}

h1,h2,h3,h4,h5,h6,legend{
    font-family: Clear Sans,Clear Sans,Clear Sans,sans-serif,sans-serif;
    font-weight:700;
    #color: #E52B50;
}
.leaflet-zoom-box {
    display: none;
}
</style>
***

## Vorwort
In diesem Projekt werden Daten verwendet, die eine Art von kompositionellen Daten (bzw. Zusammensetzungsdaten, engl. *compositional data*) darstellen. Meistens werden sie in Prozent angegeben, daher enthalten sie relative Informationen, die zu einer konstanten Zahl summieren. Diese Eigenschaft der Zusammensetzungsdaten macht viele statistische Standardansätze ungültig. In diesem Beitrag werden ein Zusammensetzungsdatensatz mit Angaben in absoluten Zahlen und die Standardmethoden für die Clusteranalyse verwendet. In Teil 2 des Projekts werden die speziell für die Zusammensetzungsdaten entwickelten Analysemethoden verwendet, um die Ergebnisse der beiden Verfahren zu vergleichen.
<br>

# 1. Einführung
Die Vorbereitung für das Superwahljahr 2021 in Berlin, in dem sowohl die Wahl zum BVV, Berliner Abgeordnetenhaus und Bundestag stattfinden, hat bereits begonnen. Eine zielgerechte Ansprache der potenziellen Wähler ist ein wichtiger Aspekt einer erfolgreichen Wahlkampagne und setzt gute Kenntnisse der demographischen Struktur sowie der politischen Präferenzen der Bürger im Wahlgebiet voraus. Die folgende Analyse soll Einblicke in die Berliner Wählerschaft im Hinblick auf die Interessen der Freien Demokraten in Pankow geben. Ziel ist es, Gruppen von Wahllokalen zu finden, die möglichst homogene Wahlergebnisse aufweisen und zwischen den unterschiedlichen Gruppen möglichst heterogen bleiben. Es wird die Clusteranalyse angewendet, um die Gebiete bzw. Wahllokale mit ähnlichen Wählerpräferenzen zu identifizieren und auf einer interaktiven Karte zu präsentieren.

In der folgenden Clusteranalyse werden ausschließlich die Wahlergebnisse der Zweitstimmen der Bundestagswahl 2017 zusammengeführt. Einbezogen sind die Stimmen aus den einzelnen Wahllokalen für die sechs Bundestagsparteien (>5% auf Bundesebene) und der restlichen Parteien, zusammenaddiert als "Sonstige". Die Stimmen der Briefwahl sind ausgeschlossen, da sie aufgrund eigener räumlicher Zuteilng, den einzelnen Wahllokalen nicht direkt zugeordnet werden können.  

Die Anwendungen der Clusteranalyse reichen von Marketing, Telekomunikation bis zu wissenschaftlichen Disziplinen wie Medizin, Soziologie, Psychologie usw. Bei den Untersuchungsobjekten kann es sich um Individuen, Gegenstände, Länder oder andere Verwaltungseinheiten handeln. Das Verfahren hilft z.B. bei einer Analyse von Kunden und liefert als Ergebnis homogene Kundengruppen (Kundensegmentierung), um durch Personalisierung einen effektiveren Kundenservice zu erreichen. Die feingranularen Daten auf der Ebene der einzelnen Wahllokale, der kleinsten Wahlregioneinheit, ermöglichen sehr präzise Bestimmung der Wählerpräferenzen in den Ortsgebieten in Berlin. Diese Informationen können beispielweise sowohl dem Bezirksverband Pankow als auch den Ortsverbänden (Prenzlauer Berg, Stadt Land Panke, Weißensee) nützliche Erkenntnisse über ihre potenziellen Wähler liefern. 

```{r setup, include = FALSE}
# Loading libraries  
knitr::opts_chunk$set(echo = TRUE)
  library(pacman)
  p_load(tidyverse, cluster, cowplot, DT, factoextra, forcats, GGally, gridExtra, htmltools, kableExtra, leaflet, leafsync, NbClust, purrr, RColorBrewer, rgdal, scales, widgetframe)
  
# Generating new ggplot theme
theme_clustpankow <- function(base_size = 11,
                      base_family = "Source Sans Pro",
                      base_line_size = base_size / 170,
                      base_rect_size = base_size / 170){
  theme_minimal(base_size = base_size, 
                base_family = base_family,
                base_line_size = base_line_size) %+replace%
    theme(
          axis.line = element_line(color = "white", size = 0.5),
          axis.title.x = element_text(color = "white", face = "bold", size = 14,
                                    margin = margin(t = 20, b = 5, unit = "pt")),
          axis.title.y = element_text(color = "white", face = "bold", size = 14, angle = 90,
                                    margin = margin(l = 5, r = 20, unit = "pt")),
          axis.text = element_text(color = "white", face = "bold"),
          axis.ticks = element_line(size = 0.5, color = "grey"),
          axis.ticks.length = unit(1, "mm"),
          legend.position = "right",
          legend.text = element_text(color = "white", face = "bold", size = 12),
          legend.title = element_text(color = "white", face = "bold", size = 14),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.spacing.x = unit(10, "mm"),
          plot.background = element_rect(fill = "black"),
          plot.title = element_text(size = 16, color = "white", face = "bold", hjust = 0.5), 
          plot.subtitle = element_text(size = 14, color = "white", face = "bold", hjust = 0.5), 
          plot.caption = element_text(size = 10, color = "white", hjust = 1),
          strip.background = element_rect(fill = "black"),
          strip.text = element_text(colour = "white", size = 12, face = "bold", 
                                    margin = margin(b = 10, unit = "pt")), 
          
      complete = TRUE
    )
}

# Color pallete
pal_clusterpankow <- c("#DB4172", "#00CC87", "#E266D3", "#0095CC")
pal_parties <- c( "AfD" = "#009EE0", "CDU" = "#383838", "FDP" = "#ffed00", 
                "SPD" = "#FF0000", "GRÜNE" = "#64A12D", "LINKE" = "#800080","Sonstige" = "grey")
```

# 2. Methodik
### 2.1. Clusteranalyse
Clusteranalyse, auch als Clustering bezeichnet, ist eine *unüberwachte* Methode des maschinellen Lernens (englisch: *unsupervised* learning), bei der ähnliche Objekte (Datenpunkte) in Gruppen unterteilt werden. Die Objekte werden in der Regel durch eine Menge von *Attributen* repräsentiert, in dieser Analyse durch die Anzahl der Stimmen für die Parteien in Berliner Wahllokalen. Die Gruppen werden als **Cluster** bezeichnet. 

Die Clusteranalyse verwendet mathematische Algorithmen, um die Gruppen ähnlicher Objekte, basierend auf den kleinsten Abweichungen zwischen den Objekten innerhalb jeder Gruppe zu ermitteln. Man möchte also eine große Datenmenge (z.B. 1779 Wahllokale in Berlin) durch eine kleinere ersetzen, die leichter zu interpretieren und zu handhaben ist, ohne dabei Informationen über die Daten zu verlieren. Es wird also versucht, aus dem vorhandenen Datensatz eine Struktur und Bedeutung zu erstellen. Die Charakterisierung der Gruppen ist vorab nicht bekannt und es sind keine im Voraus bekannten Zielwerte gegeben - deswegen wird Clustering  als *unüberwacht* bezeichnet. Die Kennzeichnung entsteht im Laufe der Analyse, im Gegensatz zur Klassifikation, bei der vorab Gruppen-Bezeichnungen definiert werden. 

Ein zentraler und zugleich schwieriger Teil der Clusteranalyse ist die Bestimmung einer optimalen Anzahl der Cluster. Die Ermittlung der Clusterzahl spielt eine wesentliche Rolle und bedingt die Qualität der Analyse. Es stehen zwar zahlreiche mathematisch begründete Entscheidungskriterien zur Vefügung, jedoch oft ergeben diese oft verschiedenen Ergebnisse und es gibt keine optimale, allgemeine Lösung. Für die Auswahl der Clusterzahl wird daher eine Reihe von Methoden herangezogen. Die Deutlichkeit der Ergebnisse sowie das am häufigsten auftretende Ergebnis werden in Betracht gezogen. 

Alle Analysen werden mit `R` - einer *open source* Programmiersprache für statistische Analysen und Datenvisualisierung durchgeführt.

### 2.2. Datensatz
Diese Clusternalyse beruht auf Zweitstimmen der Bundestagswahl 2017 im Bundesland Berlin, auf der Ebene der Wahllokale. 
Das Berliner Wahlgebiet ist in 12 Bezirke, 1779 Urnenwahlbezirke und 718 Briefwahlbezirke eingeteilt. In jedem Urnenwahlbezirk gibt es ein Wahllokal mit einem Wahlvorstand ([Wahlgebietseinteilung, berlin.de](https://www.berlin.de/wahlen/wahlen/bundestagswahl-2017/wahlgebietseinteilung/artikel.750582.php)). Ein Wahllokal entspricht der `polingarea_number` in der Datei und wird als eine 5-stellige Zahl, mit einem Zusatz "W" (Wahllokal, `pollingarea_type`='regular') an der dritten Stelle angegeben. Die zwei ersten Ziffern bezeichnen die Bezirksnummer der Stadt Berlin, die drei letzten Ziffern den Urnenwahlbezirk. Die Nummerierung der Briefwahlgebiete (`pollingarea_type`='postal') unterliegt einer anderen Notation und ist an dieser Stelle nicht weiter relevant. 


##### Tab. 1: Einblick in die Rohdaten, Bundestagswahl 2017, Berlin
```{r loaddata, echo = FALSE, warning = FALSE, message = FALSE}
# Reading in the Bundestagswahl data saved on github
btw17_Berlin <- read_csv('https://raw.githubusercontent.com/blumoestit/R_Projects/master/3.%20Cluster%20Analysis%20Bundestagswahl%20Berlin/Data/nat17_Berlin.csv')

# Taking a look at the first rows in btw17_Berlin
btw17_Berlin_head <- btw17_Berlin %>% filter(pollingarea_type == "regular") %>% head(7)
  
# kable(btw17_Berlin_head#, 
#       #caption = "Sample of Billboard chords data table"
#       ) %>%
#       kable_styling(full_width = FALSE, position = "left", bootstrap_options = "striped", font_size = 14)

kable(btw17_Berlin_head#, 
      #caption = ""
      ) %>%
      kable_styling(full_width = FALSE, position = "left", bootstrap_options = "striped", font_size = 14)
```


Die Rohdaten werden auf die *Attribute* reduziert, die für die Clusteranalyse und Erstellung einer Karte notwendig sind. Als Attribute der Wahllokale werden also die Anzahl der abgegebenen Stimmen für die Partien AfD, CDU, FDP, GRÜNE, LINKE und SPD einbezogen, sowie der Parteien, die bundesweit unter 5% der Zweitstimmen erlangten, summiert zu "Sonstige". Die Tabelle 2 zeigt die ersten Spalten der Datei verwendet in der Clusteranalyse. Die Zahlen repräsentieren die Anzahl der Zweitstimmen in Wahllokalen.


##### Tab. 2: Einblick in die ersten Spalten der Tabelle verwendet in der Clusteranalyse
```{r dataframe, echo = FALSE, warning = FALSE, message = FALSE}
# Remove DE from party names
names(btw17_Berlin) <- gsub("DE-", "", names(btw17_Berlin))

# Select main parties and sum other as "Sonstige"
btw17_to_cluster <- btw17_Berlin %>% filter(pollingarea_type == "regular") %>%
                mutate(Sonstige = select(., 12:45, -AfD, -CDU, -FDP, -GRÜNE, -LINKE, -SPD) %>% rowSums()) %>%
                select(7, 3, AfD, CDU, FDP, GRÜNE, LINKE, SPD, Sonstige) %>% 
                rename(Wahllokal = pollingarea_number)

# Data frame to numeric matrix
## numbers only
btw17_matrix <- btw17_to_cluster %>% select(-1:-2) %>% 
                data.matrix()
## with row names
btw17_matrix2 <- as.matrix(btw17_to_cluster)

## scaled values
btw17_matrix_scaled <- scale(btw17_matrix)

# Show the table prepared for clustering analysis
kable(head(btw17_to_cluster, 7)#, 
      #caption = ""
      ) %>%
      kable_styling(full_width = FALSE, position = "left", bootstrap_options = "striped", font_size = 14)
```

# 3. Anzahl der Wählergruppen - die Clusterzahl
Aus einer Reihe existierender Lösungsansätze zur Feststellung der Clusteranzahl werden hier vier Algorithmen verwendet, wobei der letzte Algorithmus selbst 26 verschiedene Methoden beinhaltet. Am häufigsten verwendete Methoden in R sind: 

* Ellenbogen-Kriterium
* Silhouetten-Koeffizient 
* Lückenstatistik (Gap Statistic Method)
* NbClust() Algorithmus

Zusammen ergeben sie eine robuste Entscheidungsgrundlage. Die theoretischen Grundlagen der Bestimmung der Clusterzahl werden in zahlreichen Beiträgen präsentiert u.a. bei [DataNovia](https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/) (in engl.) oder [Wikipedia](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set).

```{r elbowsildata, echo = FALSE, warning = FALSE, message = FALSE}
set.seed(16)
## Create a funciton to determine optimal k in elbow and silhouette plot
tot_withinss <- map_dbl(1:10, function(k) {
  model <- kmeans(x = btw17_matrix, centers = k)
  model$tot.withinss
})
    
sil_width_pam <- purrr::map_dbl(2:10, function(k){
  model <- pam(x = btw17_matrix, k = k)
  model$silinfo$avg.width
})
  
## Create df for the k = 10  
 elbow_df_baseR <- data.frame(k = 1:10,
                              parameter = tot_withinss)  %>% #parameter = tot_withins
                   mutate(k = factor(k), method = "kmeans()")

 sil_width_df_pam <- data.frame(k = 1:10,
                               parameter = c(0, sil_width_pam)) %>% #parameter = sil_width
                    mutate(k = factor(k), method = "pam()")

## Run the fviz_nbclust() from factoextra package with the kmeans() and pam() "silhouette"
elbow_df_factoextra <- fviz_nbclust(btw17_matrix, FUNcluster = kmeans, method = "wss")

silhouette_df_factoextra <- fviz_nbclust(btw17_matrix, FUNcluster = kmeans, method = "silhouette")

# Merge both methods into one data frame
## wss
elbow_two_methods <- elbow_df_factoextra[[1]] %>%
                                  rename("k" = "clusters", "parameter" = "y") %>%
                      mutate(method = "fviz_nbclust()") %>%
                      bind_rows(elbow_df_baseR) 
## silhouette
sil_two_methods <- silhouette_df_factoextra[[1]] %>%
                      rename("k" = "clusters", "parameter" = "y") %>%
                      mutate(method = "fviz_nbclust()") %>%
                      bind_rows(sil_width_df_pam) 

# Create ggplot function
  # dat: elbow_two_methods method: "tot_withinss"
  # dat: sil_two_methods method: "sil_width"

k_optimal <- 4  #value recognized from charts

optimal_cluster <- function(dat, met, nk){
  ylab <- if (met == "tot_wss") {
    "wss" #"Gesamtsumme der quadrierten Abweichungen \ninnerhalb der Cluster"
  } else if (met == "sil_width") {
    "Durchschnittlicher Silhouette-Koeffizient"
  } else if (met == "gap") {
    "Gap statistic"
  } else {
    ""
  }
  
  max_y <- if (met == "tot_wss") {
    max(elbow_two_methods$parameter)
        } else if (met == "sil_width") {
    max(sil_two_methods$parameter)
        } else if (met == "gap") {
          max(gap_df_cluster$parameter)
        } else {
          ""
        }
  
  ggplot(dat, aes(k, parameter, group = method, color = method)) +
       geom_vline(xintercept = nk, linetype = "dashed",
               size = 1, color = "white") +
       geom_point(size = 3) +
       geom_line() +
       scale_x_discrete(breaks = pretty_breaks(n = 11)) +
       scale_color_manual(values = c("#DB4174", "#0095CC"), name = "Funktion") +
       theme_clustpankow() +
       theme(panel.grid.major.x = element_blank(),
            plot.margin = margin(20, 20, 20, 20, "pt")) +
       geom_text(aes(x = nk, y = max_y,
                    label = "Optimale Anzahl der Cluster"),
                    colour = "white", angle = 0, hjust = -0.1)+
        xlab("Clusterzahl") +
        ylab(ylab) 
}
```
<br>


### 3.1. Ellbogen-Kriterium
Die wahrscheinlich bekannteste Methode ist die Ellbogenmethode, bei der die Gesamtsumme der quadrierten Abweichungen der Entfernung der Datenpunkte von dem Cluster-Zentroiden (engl. **w**ithin-cluster **s**um of **s**quare, *wss*), für eine Anzahl von Clustern berechnet und grafisch dargestellt wird. Es soll die Anzahl der Cluster ausgewählt werden, die bei einem Hinzufügen eines weiteren Clusters die *wss*-Werte nicht wesentlich verbessert. In der Kurve zeigt sich das als Änderung der Neigung von steil nach flach ("Ellbogen"). Die Position der Biegung im Diagramm wird als Ellbogen-Kriterium bezeichnet und steht als Indikator der optimalen Clusterzahl. 

Die *wss*-Werte werden für jede Clusterzahl von 1 bis 10, mittels des k-Means-Algorithmus mit der **baseR** Funktion `kmeans()` und der Funktion `fviz_nbclust()` aus dem **factoextra** package in R berechnet. Die Position des Ellbogens, damit auch die Clusterzahl, wird in der Kurve durch die vertikale Linie angezeigt. 


##### Abb. 3.1-1: Das Ellbogen-Diagramm zeigt die optimale Clusterzahl von 4. 
```{r elbow, echo = FALSE, warning = FALSE, message = FALSE}
 optimal_cluster(elbow_two_methods, "tot_wss", k_optimal)
```
<br><br>


### 3.2. Silhouetten-Koeffizient
Eine weitere Visualisierung, mit deren Hilfe die optimale Anzahl von Clustern ermittelt werden kann, wird als Silhouette-Methode bezeichnet. Die Silhouette bestimmt die Qualität der Cluster, indem ein Koeffizient zwischen -1 und 1 bestimmt wird. Dieser zeigt wie gut jede Beobachtung (hier ein Wahllokal) im jeweiligen Cluster liegt. Die Methode berechnet die durchschnittliche Silhouette der Beobachtungen für verschiedene Werte der Clusterzahl. Ein hoher durchschnittlicher Silhouetten-Koeffizient weist auf eine gute Clusterbildung hin. Die optimale Anzahl von Clustern ist diejenige, die die durchschnittliche Silhouette über einen Bereich möglicher Clusterzahlen maximiert.

Die Werte der Silhouetten-Koeffizienten für jede Clusterzahl von 1 bis 10 werden mit der Funktion `fviz_nbclust()` aus dem **factoextra** package and `pam()` aus dem **cluster** package in R berechnet. Ein maximaler Wert ergibt sich bei der Clusterzahl 4. 


##### Abb. 3.2-1: Der Silhouetten-Koeffizient zeigt die optimale Clusterzahl von 4.
```{r silhouette1, echo = FALSE, warning = FALSE, message = FALSE}
optimal_cluster(sil_two_methods, "sil_width", k_optimal)
```


Die Silhouetten unseres Datensatzes für die Clusterzahl 4 zeigt der sogennante Silhouettenplot. Für alle Beobachtungen (in unserem Fall für alle Wahllokale) die zu einem Cluster gehören, werden die Silhouette-Koeffizienten auf der senkrechten Achse angegeben und innerhalb jedes Clusters nach der Größe der Koeffizienten geordnet. Der durchschnittliche Silhouetten-Koeffizient aller Cluster wird mit der waagerechten roten Linie markiert.


##### Abb. 3.2-2: Optimale Clusterzahl aus der Silhouetten Methode mit eclust() aus dem factoextra package
```{r silhouette2, echo = FALSE, warning = FALSE, message = FALSE}
set.seed(16)
# Visual Enhancement of Clustering Analysis
enhanced_kmean <- eclust(btw17_matrix, "kmeans", graph = FALSE)

# Visualize silhouette with ggplot
fviz_silhouet <- fviz_silhouette(enhanced_kmean, print.summary = FALSE, palette = pal_clusterpankow,
             ggtheme = theme_clustpankow()) + ggtitle("Durschnittliche Silhouette-Koeffizient: 0.3") +
              labs(x = "Cluster", y = "Silhouette-Koeffizient", fill = "Clusternummer") +
  scale_color_manual(guide = FALSE, values = c("#DB4172", "#00CC87", "#E266D3", "#0095CC")) 

fviz_silhouet
#enhanced_kmean$silinfo$clus.avg.widths
```
<br><br>


### 3.3. Lückenanalyse (Gap Statistic)
Die Lückenstatistik (engl. *gap statistic*) von [Tibshirani et al. (2001)](https://web.stanford.edu/~hastie/Papers/gap.pdf) vergleicht die Summe der durchschnittlichen Streuung (engl. *within intra-cluster variation*) innerhalb des Clusters für eine zunehmende Anzahl von Clustern zu einer Referenzverteilung ohne offensichtlichen Clusterbildung. Der Wert, der die Lückenstatistik maximiert, stellt die optimale Clusterzahl dar. Der maximale Wert ergibt die größte Lückenstatistik und bedeutet, dass die Clusterstruktur sich am weitesten von der zufälligen, gleichmäßigen Referenzverteilung unterscheidet.
Die Werte der Lückenstatistik und die optimale Anzahl der Cluster werden mit der `clusGap()`Funktion aus dem **cluster** package ermittelt. Diese Methode schlägt für unseren Datensatz nur 1 Cluster vor. Damit gibt die Methode keinen Hinweis darauf, ob der Datensatz überhaupt in Cluster unterteilt werden soll. 


##### Abb. 3.3-1: Optimale Clusterzahl aus der Lückenanalyse des cluster package
```{r gapstatistics, echo = FALSE, warning = FALSE, message = FALSE}
# Use the clusGap() to apply the Gap Statistic Method
gap_stat <- clusGap(btw17_matrix_scaled, FUN = kmeans, nstart = 25, K.max = 10, B = 10)

# Extract recommended number of clusters
k_optimal_gap <- maxSE(gap_stat$Tab[, "gap"], gap_stat$Tab[, "SE.sim"], method="Tibs2001SEmax")

# Create a data frame for ggplot
gap_df_cluster <- data.frame(k = 1:10,
                              parameter = gap_stat$Tab[,3])  %>% 
                   mutate(k = factor(k), method = "clusGap()")

# # Use the fviz_gap_stat function to vizualize the results
#gap_stat_method <- fviz_gap_stat(gap_stat)

# View the plot
optimal_cluster(gap_df_cluster, "gap", k_optimal_gap)
```
<br><br>


### 3.4. NbClust() 
Die vierte Alternative ist die `NbClust()` Funktion aus dem NbClust package in R. Die Funktion umfasst 26 Methoden zur Bestimmung der optimalen Clusterzahl und schlägt die Lösung vor, welche am häufigsten auftritt. Die Details können in [Charrad et al. (2014)](https://www.jstatsoft.org/article/view/v061i06) nachgelesen werden. 

Zwei von den 26 Methoden, der Hubert-Index und der D-Index, sind rein grafische Methoden (siehe Diagramme unten). Die optimale Anzahl von Clustern befindet sich in einem „Ellbogenpunkt“, nach dem der entsprechende statistische Wert in der zweiten Differenz (ein Wert aus der Differentialrechnung) stark abnimmt. Beide Methoden zeigen einen Ellbogen für unseren Datensatz bei der Clusterzahl 4.


##### Abb. 3.4-1: Optimale Clusterzahl aus der Hubert-Index und der D-Index Methoden
```{r nbclust1, echo = FALSE, warning = FALSE, message = FALSE, results = "hide", out.width = '55%'}
# Use the NbClust() to obtain number of clusters from 26 models
nbclust_stat <- NbClust(data = btw17_matrix, distance = "euclidean", method = "kmeans",
                        min.nc = 2, max.nc = 10) # min and max number of clusters

# nbclust_stat_dindex <- NbClust(data = btw17_matrix, distance = "euclidean", method = "kmeans",
#                         min.nc = 2, max.nc = 10, index = "dindex") 
# nbclust_stat_dindex
```

Die Ergebnise der 26 Methoden aus der NbClust() Funktion werden hier in einem Balkendiagramm präsentiert. Der am häufigsten auftretende Wert bestimmt 4 als die optimale Clusterzahl. 


##### Abb. 3.4-2: Die Häufigkeit der Clusterzahlen aus der NbClust() Funktion
```{r nbclust2, echo = FALSE, warning = FALSE, message = FALSE}
nbclust_number_cluster <- tibble::as_tibble(nbclust_stat$Best.nc[1, ])

ggplot(nbclust_number_cluster, aes(value)) +
       geom_bar(fill = "#E52B50") +
       scale_x_continuous(breaks = pretty_breaks(n = 11)) +
       scale_y_continuous( expand = c(0, 0, 0, 1)) +
       theme_clustpankow() +
       theme(panel.grid.major.x = element_blank(),
             plot.margin = margin(20, 20, 20, 20, "pt")) +
         ggtitle("Optimale Anzahl der Cluster aus 26 Modellen") +
         xlab("Anzahl der Cluster") +
         ylab("Häufigkeit unter allen Indizes")
```
<br><br>


### 3.5. Clustertendenz des Datensatzes - die Hopkins-Statistik
```{r hopkins, echo = FALSE, warning = FALSE, message = FALSE}
hopkins <- factoextra::get_clust_tendency(data = btw17_matrix, n = 50, graph = FALSE)
hopkins_statistik <- round(hopkins$hopkins_stat, 2)
```

Die meisten Methoden zur Feststellung der Anzahl von Clustern zeigen vier Cluster als eine optimale Lösung für unseren Datensatz. Dennoch hat das Ergebnis der Lückenstatistik keine Cluster "entdeckt" und deutet auf einen uniformen Datensatz hin. Um die Eignung des Datensatzes für Clustering zu testen, führen wir einen diagnostischen Test zu Beurteilung der Clustertendenz unseres Datensatzes, mit der sogenannten **Hopkins-Statistik** (Lawson & Jurs, 1990) durch. Diese Methode bestimmt die Wahrscheinlichkeit, dass ein Datensatz durch eine gleichmäßige Datenverteilung generiert wird. Mit anderen Worten, sie testet die räumliche Zufälligkeit der Daten. Wir verwenden die `get_clust_tendency()` Funktion aus dem **factoextra** package. Ein Wert für Hopkins-Statistik von mehr als 0.5 zeigt eine Clusterbildungstendenz bei einem Konfidenzniveau von 90% an [Kassambara 2017, p.97](https://books.google.de/books?id=plEyDwAAQBAJ&printsec=frontcover&hl=de&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false). Das Ergebnis der Hopkins-Statistik für unseren Datensatz beträgt `r hopkins_statistik`. Es ist ersichtlich, dass der Datensatz stark clusterfähig ist, da der Wert weit von dem Schwellenwert 0.5 entfernt liegt. Auf die Visualisierung wird an dieser Stelle verzichtet. 

##### Zusammenfassend: 

- Unser Datensatz zeigt deutliche Tendenz zur Clusterbildung; 
- Die meisten Methoden zeigen die optimale Anzahl der Cluster bei 4; 
- Mit dieser Festlegung der Clusterzahl von 4 wird anschließend die Clusternalyse mit dem k-Means Algorithmus durchgeführt.
<br>

# 4. Die Cluster als  Wählergruppen
### 4.1. Wahlergebnisse in Clustern im Vergleich zu Berlin und Pankow
Das k-Means-Clustering [(MacQueen, 1967)](https://www.cs.cmu.edu/~bhiksha/courses/mlsp.fall2010/class14/macqueen.pdf) (engl. mean = Mittelwert) ist einer der am häufigst verwendeten *unüberwachten* Algorithmen für maschinelles Lernen zum Partitionieren eines Datensatzes in *k* Gruppen (bzw. *k* Clustern), wobei *k* die Anzahl der vom Analysten vorgegebenen Cluster darstellt. Es klassifiziert Objekte in mehrere Cluster, sodass diese Objekte innerhalb desselben Clusters so ähnlich wie möglich sind (hohe Ähnlichkeit innerhalb der Gruppe), während Objekte aus verschiedenen Clustern so unterschiedlich wie möglich sind. Beim k-Means-Clustering wird jeder Cluster durch sein Zentroid (oder Schwerpunkt, engl. centroid) dargestellt, das dem Mittelwert der dem Cluster zugewiesenen Punkte entspricht.

Die Schwerpunkte der Cluster werden durch die gleichen Attribute wie der gesamte Datensatz repräsentiert, in unserer Analyse sind das die Mittlere Anzahl der Zweitstimmen, welche die Wahlergebnisse darstellen. Das Balkendiagramm zeigt, wie stark die Unterschiede zwischen den vier Clustern sind und wie sie im Vergleich mit den Wahlergebnissen im Bezirk Pankow und der Stadt Berlin stehen.


##### Abb. 4.1-1: Vergleich der Wahlergebnisse zwischen den Clustern, Bezirk Pankow und Stadt Berlin
```{r percentage_clusters, echo = FALSE, warning = FALSE, message = FALSE}
set.seed(2017)
kmeans_4_cluster <- kmeans(x = btw17_matrix, centers = 4, iter.max = 50)

parties_means <- as.data.frame(kmeans_4_cluster$centers) %>% 
  mutate(unit = as.character(row_number())) %>% 
  gather(key = Party, value = votes, -unit) %>% 
  group_by(unit) %>% 
  mutate(percentage = votes/sum(votes)) 

# Resultd for Berlin and Pankow
Pankow_Berlin <- data.frame(Party = rep(c("AfD", "CDU", "FDP", "GRÜNE", "LINKE", "SPD", "Sonstige"), 2), 
                            unit = c(rep("Berlin", 7), rep("Pankow", 7)),
                            percentage = c(0.12, 0.227, 0.089, 0.126, 0.188, 0.179, 0.071, 
                                           0.125, 0.198, 0.066, 0.143, 0.235, 0.156, 0.077),
                            votes = rep(0 ,14))
                            
# Join both tables
parties_percentages <- parties_means %>% bind_rows(Pankow_Berlin)

parties_percentages$Party <- factor(parties_percentages$Party, levels = c("AfD", "CDU", "FDP", "GRÜNE", "LINKE", "SPD", "Sonstige"))
parties_percentages$unit <- factor(parties_percentages$unit, levels = c("Berlin", "Pankow", "1", "2", "3", "4"))
                                
# Create chart of % votes for parties 
  ggplot(parties_percentages, aes(fct_rev(unit), percentage, fill = fct_rev(Party))) +
       geom_col(width = 0.8) +
       coord_flip() +
       scale_x_discrete() +
       scale_y_continuous(expand = c(0, 0, 0, 0), labels = percent_format(accuracy = 1), 
                          breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_fill_manual(values = pal_parties, guide = guide_legend(reverse = TRUE)) +
       theme_clustpankow() +
       theme(panel.grid.major.x = element_line(size = 0.5, linetype = "solid", color = "grey"),
             plot.margin = margin(20, 20, 20, 20, "pt"),
             axis.line.x = element_blank()) +
         labs(fill = "", 
              x = "Cluster,  Bezirk,  Stadt",
              y = "% der Zweitestimmen") +
       geom_text(aes(label = percent(percentage, accuracy = 0.1)), position = position_stack(0.5),
                 color = ifelse(parties_percentages$Party == "FDP", paste("black"), paste("white")), 
                 fontface = "bold", size = 3.2)
```


Die Wahlergebnisse in den Clustern zeigen spezifische politische Tendenzen. Damit lassen sich die vier Cluster als vier Wählergruppen identifizieren. Wenn man die Prozentzahlen der Parteien in den Clustern mit den gesamten Ergebnissen der Stadt Berlin vergleicht, ergibt sich folgendes:

* Cluster 1 - **CDU** und **FDP** mit höheren Ergebnissen im Vergleich zu Stadt Berlin, mit gesamt 39,9% - *konservativ-liberal* 
* Cluster 2 - nah am Berliner Durchschnitt, **rot-rot-grün** gesamt 47,8% - *rot-rot-grün* 
* Cluster 3 - dominiert **LINKE** 26,9% und **GRÜNE** 21,9% - *sozial-ökologisch* 
* Cluster 4 - dominiert **LINKE** 25,2% und **AfD** 20,4% - *sozial-konservativ* 

Der Anteil der Wahllokale in den vier Clustern zeigt eine völlig andere Verteilung in Pankow als im Vergleich zu der Stadt Berlin. Die Zahlen über den Diagramm-Balken repräsentieren die Anzahl der Wahllokale in den Wahlregionen Berlin und Pankow. Der Bezirk Pankow ist auf 154 Wahllokale geteilt, was dem Anteil von 8,7% der Wahllokale der Stadt Berlin entspricht. 


##### Abb. 4.1-2: Vergleich der Anteile der Cluster in Bezirk Pankow zu Stadt Berlin
```{r number_wahllokale, echo = FALSE, warning = FALSE, message = FALSE}
# Create a plot showing comparison of Wahllokal amounts in Berlin and Pankow
# Data
btw17_to_cluster_to_table <- btw17_to_cluster %>% 
                             dplyr::select(Bezirk, Wahllokal) %>% 
                             bind_cols(as_tibble(kmeans_4_cluster$cluster)) %>% 
                             rename("Cluster" = "value")


btw17_to_cluster_amount_Berlin <- btw17_to_cluster_to_table %>% 
                                  group_by(Cluster) %>% 
                                  count() %>% 
                                  mutate(Wahlregion = "Berlin")

btw17_to_cluster_amount_Pankow <- btw17_to_cluster_to_table %>% 
                                  filter(Bezirk == "Pankow") %>% 
                                  count(Cluster) %>% 
                                  mutate(Wahlregion = "Pankow")

btw17_to_cluster_amount_table <- bind_rows(btw17_to_cluster_amount_Berlin, btw17_to_cluster_amount_Pankow) %>%
                                 group_by(Wahlregion) %>% 
                                 mutate(n_percent = n/sum(n)) %>% 
                                 mutate(Cluster = as.character(Cluster)) 
                                 
btw17_to_cluster_amount_table$Cluster <- recode(btw17_to_cluster_amount_table$Cluster, 
                                                  "1"= "konserv.-liberal",
                                                  "2" = "rot-rot-grün",
                                                  "3" = "sozial-ökolog.",
                                                  "4" = "sozial-konserv.")

# Plot
btw17_to_cluster_amount_table %>% ggplot(aes(x = Cluster, y = n_percent, fill = Wahlregion)) +
                                  geom_col(position = "dodge") +
                                  scale_y_continuous(expand = c(0, 0), 
                                                     labels = percent_format(accuracy = 1),
                                                     limits = c(0, 0.5)) + 
                                  scale_fill_manual(values = c("#C53B63", "#00857C")) +
                                  theme_clustpankow() +
                                  theme(plot.margin = margin(20, 10, 20, 40, "pt"),
                                        axis.title = element_blank()) +
                                  geom_text(aes(label = percent(n_percent, accuracy = 0.1)), 
                                                position = position_dodge(1), 
                                                vjust = 1.5,color = "white") +
                                  geom_text(aes(label = n), 
                                                position = position_dodge(1), 
                                                vjust = -0.5,color = "white")
```
<br><br>


### 4.2. Die Karten 
Die folgende Karten zeigen die Ergebnisse unserer Clusteranalyse (interaktiv) sowie der Bundestagswahl 2017 mit dem Fokus auf den Bezirk Pankow. Ein Vergleich der Anordnung der Cluster mit den Ergebnissen für die sechs Bundestagsparteien zeigt ein konsistentes Bild. Die "Muster" der Cluster überlappen sich mit den Intensitäten der Farben, die die Ergebnisse der Zweitstimmen repräsentieren.


##### Abb. 4.2-1: Räumliche Anordnung der Cluster in Berlin
```{r data_to_map, echo = FALSE, warning = FALSE, message = FALSE}
btw17_to_map <- btw17_to_cluster %>% 
            bind_cols(as_tibble(kmeans_4_cluster$cluster)) %>% 
            rename("Cluster" = "value") %>% 
            mutate(votes_total = rowSums(select(., AfD:Sonstige))) %>% 
            mutate(AfD_perc = AfD/votes_total, CDU_perc = CDU/votes_total, FDP_perc = FDP/votes_total,
                   GRÜNE_perc = GRÜNE/votes_total, LINKE_perc = LINKE/votes_total, SPD_perc = SPD/votes_total, 
                   Sonstige_perc = Sonstige/votes_total, Wahllokal = as.character(Wahllokal)) %>%
            select(1:2, Cluster, votes_total, everything())

btw17_to_map$Wahllokal <- gsub("W", "", btw17_to_map$Wahllokal)
#write_csv(btw17_to_map, "/Users/magdalenablum-oeste/Google Drive/GitHubMBO/R_Projects/3. Cluster Analysis Bundestagswahl #Berlin/btw17_to_map_clusters.csv")
```

```{r map_cluster1, include = FALSE}
# Shape file Bezirke Berlin
bezirke <- readOGR("/Users/magdalenablum-oeste/Documents/FDP/BezirkStatistik/Bezirke__Berlin/Bezirke__Berlin.shp")

# Shape file Wahlkreise Berlin
UWB <- readOGR("/Users/magdalenablum-oeste/Desktop/Wahlbezirke_-_Berlin-shp/Wahlbezirke.shp")
UWBst <- spTransform(UWB, CRS("+proj=longlat +datum=WGS84"))
```


```{r map_cluster2, echo = FALSE, warning = FALSE, message = FALSE}
btw17_to_map$Cluster <- recode(btw17_to_map$Cluster, 
                                                  "1"= "konserv.-liberal",
                                                  "2" = "rot-rot-grün",
                                                  "3" = "sozial-ökolog.",
                                                  "4" = "sozial-konserv.")
UWBst@data <- UWBst@data %>% mutate(Wahllokal = str_c(BEZ, "", UWB))
UWBst@data <- UWBst@data %>% left_join(btw17_to_map)

labels <- sprintf("<strong>%s</strong><br/> 
                  Wahllokal: %s <br/> 
                  Stimmen total:  %s<br/>
                  Zweitstimmen FDP:  %s<br/>
                  In Prozent:  %s ",
                  UWBst@data$Bezirk, UWBst@data$Wahllokal, UWBst@data$votes_total, UWBst@data$FDP, percent(UWBst@data$FDP_perc, accuracy = 0.01)) %>% 
                  lapply(htmltools::HTML)
 

fact_pal <- colorFactor(palette = c("#1c2232", "#ee3557", "dodgerblue3", "springgreen2"),
                        domain = UWBst@data$Cluster)

# Create leaflet map with clusters
 map_cluster <- leaflet() %>%
  setView(lng = 13.4317, lat = 52.5928, zoom = 11) %>% 
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(data = bezirke,
              weight = 3,
              color = "black",
              fillColor = "transparent") %>% 
  addPolygons(data = UWBst,
              weight = 0.8,
              color = "white",
              fillColor = ~fact_pal(Cluster),
              fillOpacity = 0.6,
              highlight = highlightOptions(weight = 3,
                                           color = "red",
                                           fillOpacity = 0.18,
                                           bringToFront = TRUE),
              label = labels,
              labelOptions = labelOptions(textsize = "15px",
                                          style = list("font-weight" = "normal", 
                                          padding = "3px 8px"),
                                          direction = "auto")) %>% 
   addLegend(pal = fact_pal, 
             values = UWBst@data$Cluster, 
             opacity = 0.8, 
             title = "Wählergruppe (Cluster)",
             position = "bottomright") #%>% 
  #frameWidget()
map_cluster
```
<br>

##### Abb. 4.2-2: Räumliche Anordnung der Wahlergebnisse in Pankow 
```{r maps_parties_fun, echo = FALSE, warning = FALSE, message = FALSE, results=FALSE}

map_party <- function(party){

color_party <- if (party == "AfD") {paste("Blues")
  } else if (party == "CDU") {paste("Greys")
  } else if (party == "FDP") {paste("YlOrBr")
  } else if (party == "GRÜNE") {paste("Greens")
  } else if (party == "LINKE") {paste("Purples")
  } else if (party == "SPD") {paste("Reds")}

data_party <- if (party == "AfD") {UWBst@data$AfD_perc*100
  } else if (party == "CDU") {UWBst@data$CDU_perc*100
  } else if (party == "FDP") {UWBst@data$FDP_perc*100
  } else if (party == "GRÜNE") {UWBst@data$GRÜNE_perc*100
  } else if (party == "LINKE") {UWBst@data$LINKE_perc*100
  } else if (party == "SPD") {UWBst@data$SPD_perc*100}

name_party <- if (party == "AfD") {var1 = "AfD_perc"
                                    assign(var1, data_party)
                                    AfD_perc 
  } else if (party == "CDU") {var1 = "CDU_perc"
                                    assign(var1, data_party)
                                    CDU_perc 
  } else if (party == "FDP") {var1 = "FDP_perc"
                                    assign(var1, data_party)
                                    FDP_perc 
  } else if (party == "GRÜNE") {var1 = "GRÜNE_perc"
                                    assign(var1, data_party)
                                    GRÜNE_perc 
  } else if (party == "LINKE") {var1 = "LINKE_perc"
                                    assign(var1, data_party)
                                    LINKE_perc 
  } else if (party == "SPD") {var1 = "SPD_perc"
                                    assign(var1, data_party)
                                    SPD_perc }

labels_party <- sprintf("<strong>%s</strong><br/> 
                  Wahllokal: %s <br/> 
                  Stimmen total:  %s<br/>
                  Zweitstimmen Partei:  %s<br/>
                  Anzahl Zweitstimmen FDP:  %s<br/>
                  In Prozent FDP:  %s",
                  UWBst@data$Bezirk, UWBst@data$Wahllokal, UWBst@data$votes_total, paste0(round(data_party, digits = 2), "%"),
                  UWBst@data$FDP, percent(UWBst@data$FDP_perc, accuracy = 0.01)) %>% 
                  lapply(htmltools::HTML)


pal_num <- colorNumeric(color_party, domain = data_party, reverse = FALSE)

leaflet(#option=leafletOptions(zoomControl=FALSE)
  ) %>%
  setView(lng = 13.4317, lat = 52.5928, zoom = 11) %>% 
  addProviderTiles("CartoDB.Positron") %>%  #"CartoDB.Positron"
  addPolygons(data = bezirke,
              weight = 3,
              color = "black",
              fillColor = "transparent") %>% 
  addPolygons(data = UWBst,
              weight = 0.8,
              color = "white",
              fillColor = ~pal_num(name_party),
              fillOpacity = 0.6,
              highlight = highlightOptions(weight = 3,
                                           color = "red",
                                           fillOpacity = 0.18,
                                           bringToFront = TRUE),
              label = labels_party,
              labelOptions = labelOptions(textsize = "15px",
                                          style = list("font-weight" = "normal", 
                                          padding = "3px 8px"),
                                          direction = "auto")
              ) %>% 
   addLegend(pal = pal_num, 
             values = data_party, 
             opacity = 0.8, 
             title = paste0("%", " ", party), 
             position = "bottomright")
}

```

```{r maps_parties1, echo = FALSE, warning = FALSE, message = FALSE, fig.height=3, fig.width=2.4}
map_A <- map_party("AfD")
map_C <- map_party("CDU")
map_F <- map_party("FDP")
map_G <- map_party("GRÜNE")
map_L <- map_party("LINKE")
map_S <- map_party("SPD")

map_ACFGLS <- sync(map_A, map_C, map_F, map_G, map_L, map_S) # sync() from leafsync package
map_ACFGLS
```

```{r white_space, echo = FALSE, warning = FALSE, message = FALSE, fig.height = 0.1}
ggplot() + theme_void() # to keep space between maps and text, the syncronized leaflet maps overlap the next header
```


# 5. Zusammenfassung
Unsere Clusteranalyse der Bundestagswahlen 2017 in Berlin und Pankow liefert interpretierbare Ergebnisse mit drei wichtigen Erkenntnissen: 

*  In der Wählerschaft Berlins lassen sich vier Typen identifizieren, die kurz als: 1) **konservativ-liberal**, 2) **rot-rot-grün**, 3) **sozial-ökologisch**  und 4) **sozial-konservativ** bezeichnet werden können;
* Der Anteil der Wahllokale, die die bestimmten Wählertypen bzw. Cluster repräsentieren, unterscheiden sich deutlich von der Stadt Berlin. Die meisten Wahllokale in Pankow repräsentieren die **sozial-ökologischen** (44.8% der Wahllokale) und die **sozial-konservativen** (42.2% der Wahllokale) Wählertypen; 
* Das "Muster" in dem die Cluster in Berlin angeordnet sind, deckt sich direkt mit den Wahlergebnissen der Zweitstimmen der Bundestagswahl 2017 in Berlin.

Die räumliche Anordnung der Wählerschaften kann einfach auf einer Karte dargestellt werden und gibt einen Hinweis auf die politischen Präferenzen der meisten Bürger in bestimmten Ortsteilen und kleineren räumlichen Einheiten, bezogen auf die Wahllokale. Die Karte kann damit bei der Vorbereitung auf den Wahlkampf eine hilfreiche Unterstützung darstellen.


